{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnBOJh16BmKB"
   },
   "source": [
    "## Step 1 install package using github repository: https://github.com/Trusted-AI/AIF360.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l-InxqvzBr4z",
    "outputId": "36b67394-8e89-406d-de22-cf2244b676e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting git+https://github.com/pg2374/AIF.git\n",
      "  Cloning https://github.com/pg2374/AIF.git to /tmp/pip-req-build-8ufx28dy\n",
      "  Running command git clone -q https://github.com/pg2374/AIF.git /tmp/pip-req-build-8ufx28dy\n",
      "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.8/dist-packages (from aif360==0.4.0) (1.21.6)\n",
      "Collecting scipy<1.6.0,>=1.2.0\n",
      "  Downloading scipy-1.5.4-cp38-cp38-manylinux1_x86_64.whl (25.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.8 MB 1.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.8/dist-packages (from aif360==0.4.0) (1.3.5)\n",
      "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.8/dist-packages (from aif360==0.4.0) (1.0.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from aif360==0.4.0) (3.2.2)\n",
      "Collecting tempeh\n",
      "  Downloading tempeh-0.1.12-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->aif360==0.4.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->aif360==0.4.0) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->aif360==0.4.0) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.1->aif360==0.4.0) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.1->aif360==0.4.0) (3.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->aif360==0.4.0) (1.4.4)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->aif360==0.4.0) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->aif360==0.4.0) (0.11.0)\n",
      "Collecting shap\n",
      "  Downloading shap-0.41.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (575 kB)\n",
      "\u001b[K     |████████████████████████████████| 575 kB 58.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from tempeh->aif360==0.4.0) (2.23.0)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.8/dist-packages (from tempeh->aif360==0.4.0) (3.6.4)\n",
      "Collecting memory-profiler\n",
      "  Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from memory-profiler->tempeh->aif360==0.4.0) (5.4.8)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.8/dist-packages (from pytest->tempeh->aif360==0.4.0) (1.4.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from pytest->tempeh->aif360==0.4.0) (57.4.0)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.8/dist-packages (from pytest->tempeh->aif360==0.4.0) (0.7.1)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from pytest->tempeh->aif360==0.4.0) (1.11.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytest->tempeh->aif360==0.4.0) (9.0.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from pytest->tempeh->aif360==0.4.0) (22.1.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->tempeh->aif360==0.4.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->tempeh->aif360==0.4.0) (2022.12.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->tempeh->aif360==0.4.0) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->tempeh->aif360==0.4.0) (1.24.3)\n",
      "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.8/dist-packages (from shap->tempeh->aif360==0.4.0) (4.64.1)\n",
      "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.8/dist-packages (from shap->tempeh->aif360==0.4.0) (21.3)\n",
      "Collecting slicer==0.0.7\n",
      "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.8/dist-packages (from shap->tempeh->aif360==0.4.0) (0.56.4)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from shap->tempeh->aif360==0.4.0) (1.5.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba->shap->tempeh->aif360==0.4.0) (0.39.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba->shap->tempeh->aif360==0.4.0) (5.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba->shap->tempeh->aif360==0.4.0) (3.11.0)\n",
      "Building wheels for collected packages: aif360\n",
      "  Building wheel for aif360 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for aif360: filename=aif360-0.4.0-py3-none-any.whl size=599953 sha256=f35861d5cbad7c0899fe32336bf34e76f199101f67cbf6bc3a7ce636cd177abf\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-qz_rseve/wheels/71/13/55/3e9ee7172da0c15a9c49057274435b60135ce5818112294d4b\n",
      "Successfully built aif360\n",
      "Installing collected packages: scipy, slicer, shap, memory-profiler, tempeh, aif360\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.7.3\n",
      "    Uninstalling scipy-1.7.3:\n",
      "      Successfully uninstalled scipy-1.7.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "xarray-einstats 0.4.0 requires scipy>=1.6, but you have scipy 1.5.4 which is incompatible.\u001b[0m\n",
      "Successfully installed aif360-0.4.0 memory-profiler-0.61.0 scipy-1.5.4 shap-0.41.0 slicer-0.0.7 tempeh-0.1.12\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/pg2374/AIF.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SqPcufCON-r5",
    "outputId": "fe038b0c-6021-419a-bac5-66ccf4be4a49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting fairlearn\n",
      "  Downloading fairlearn-0.8.0-py3-none-any.whl (235 kB)\n",
      "\u001b[K     |████████████████████████████████| 235 kB 14.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from fairlearn) (1.21.6)\n",
      "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.8/dist-packages (from fairlearn) (1.0.2)\n",
      "Requirement already satisfied: pandas>=0.25.1 in /usr/local/lib/python3.8/dist-packages (from fairlearn) (1.3.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from fairlearn) (1.5.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.25.1->fairlearn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.25.1->fairlearn) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25.1->fairlearn) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.1->fairlearn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.1->fairlearn) (3.1.0)\n",
      "Installing collected packages: fairlearn\n",
      "Successfully installed fairlearn-0.8.0\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.9.2)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.1.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.28.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (5.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow) (3.0.9)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting scikit-plot\n",
      "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.8/dist-packages (from scikit-plot) (1.0.2)\n",
      "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.8/dist-packages (from scikit-plot) (1.5.4)\n",
      "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.8/dist-packages (from scikit-plot) (1.2.0)\n",
      "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from scikit-plot) (3.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.21.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.0->scikit-plot) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->scikit-plot) (3.1.0)\n",
      "Installing collected packages: scikit-plot\n",
      "Successfully installed scikit-plot-0.3.7\n"
     ]
    }
   ],
   "source": [
    "!pip install fairlearn\n",
    "!pip install tensorflow\n",
    "!pip install scikit-plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_3N4TC2Mujk"
   },
   "source": [
    "# Step 2: Download the data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RYLDPiR8LtMl",
    "outputId": "1b89c342-ad4c-411b-80a0-0bff115c260c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-23 06:04:05--  https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3974305 (3.8M) [application/x-httpd-php]\n",
      "Saving to: ‘adult.data’\n",
      "\n",
      "adult.data          100%[===================>]   3.79M  3.07MB/s    in 1.2s    \n",
      "\n",
      "2022-12-23 06:04:08 (3.07 MB/s) - ‘adult.data’ saved [3974305/3974305]\n",
      "\n",
      "--2022-12-23 06:04:08--  https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2003153 (1.9M) [application/x-httpd-php]\n",
      "Saving to: ‘adult.test’\n",
      "\n",
      "adult.test          100%[===================>]   1.91M  1.77MB/s    in 1.1s    \n",
      "\n",
      "2022-12-23 06:04:10 (1.77 MB/s) - ‘adult.test’ saved [2003153/2003153]\n",
      "\n",
      "--2022-12-23 06:04:10--  https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5229 (5.1K) [application/x-httpd-php]\n",
      "Saving to: ‘adult.names’\n",
      "\n",
      "adult.names         100%[===================>]   5.11K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-12-23 06:04:11 (114 MB/s) - ‘adult.names’ saved [5229/5229]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQLJaXqvM4_U"
   },
   "source": [
    "# Step 3: Copy the data files to the location specified in the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "meTD1brUMN2t"
   },
   "outputs": [],
   "source": [
    "!cp adult.data /usr/local/lib/python3.8/dist-packages/aif360/data/raw/adult/\n",
    "!cp adult.test /usr/local/lib/python3.8/dist-packages/aif360/data/raw/adult/\n",
    "!cp adult.names /usr/local/lib/python3.8/dist-packages/aif360/data/raw/adult/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6a9Iic3CBmKF"
   },
   "source": [
    "#### This notebook demonstrates the use of adversarial debiasing algorithm to learn a fair classifier.\n",
    "Adversarial debiasing [1] is an in-processing technique that learns a classifier to maximize prediction accuracy and simultaneously reduce an adversary's ability to determine the protected attribute from the predictions. This approach leads to a fair classifier as the predictions cannot carry any group discrimination information that the adversary can exploit. We will see how to use this algorithm for learning models with and without fairness constraints and apply them on the Adult dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rQs9mlkrBmKF"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult, load_preproc_data_compas, load_preproc_data_german\n",
    "\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3zETpv7BmKG"
   },
   "source": [
    "#### Load dataset and set options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JSNw_LV7BmKG"
   },
   "outputs": [],
   "source": [
    "# Get the dataset and split into train and test\n",
    "dataset_orig = load_preproc_data_adult()\n",
    "\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "Mfe7Z4VCBmKG",
    "outputId": "e7846794-5e5e-48fe-c63f-a94fd1c680fd"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34189, 18)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Test Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14653, 18)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex', 'race']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.]), array([1.])] [array([0.]), array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['race', 'sex', 'Age (decade)=10', 'Age (decade)=20', 'Age (decade)=30', 'Age (decade)=40', 'Age (decade)=50', 'Age (decade)=60', 'Age (decade)=>=70', 'Education Years=6', 'Education Years=7', 'Education Years=8', 'Education Years=9', 'Education Years=10', 'Education Years=11', 'Education Years=12', 'Education Years=<6', 'Education Years=>12']\n"
     ]
    }
   ],
   "source": [
    "# print out some labels, names, etc.\n",
    "display(Markdown(\"#### Training Dataset shape\"))\n",
    "print(dataset_orig_train.features.shape)\n",
    "display(Markdown(\"#### Test Dataset shape\"))\n",
    "print(dataset_orig_test.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_orig_train.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(dataset_orig_train.privileged_protected_attributes, \n",
    "      dataset_orig_train.unprivileged_protected_attributes)\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_orig_train.feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "sWK8ml-5RV3a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UeLD9RxcBmKH"
   },
   "source": [
    "#### Metric for original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "id": "StftAD4CBmKH",
    "outputId": "53bab761-0458-4f6e-d939-f03057f01866"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.191948\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.200418\n"
     ]
    }
   ],
   "source": [
    "# Metric for the original dataset\n",
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "metric_orig_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_test.mean_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKCBoIILBmKI"
   },
   "source": [
    "# Part 1: Original work by author\n",
    "##In each part, we have added addtional metrics like precision and recall to gauge performance on imbalanced data\n",
    "### Preprocessing dataset using MaxAbsScaler</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "id": "Ap2uDRHXBmKI",
    "outputId": "47853c68-03c7-4350-e4cc-3683e9cb0e7b"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Scaled dataset - Verify that the scaling does not affect the group label statistics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.191948\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.200418\n"
     ]
    }
   ],
   "source": [
    "max_abs_scaler = MaxAbsScaler()\n",
    "dataset_orig_train.features = max_abs_scaler.fit_transform(dataset_orig_train.features)\n",
    "dataset_orig_test.features = max_abs_scaler.transform(dataset_orig_test.features)\n",
    "metric_scaled_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Scaled dataset - Verify that the scaling does not affect the group label statistics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_train.mean_difference())\n",
    "metric_scaled_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_test.mean_difference())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_dr35JiBmKI"
   },
   "source": [
    "### Learn plain classifier without debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "AuRr4hwDBmKI"
   },
   "outputs": [],
   "source": [
    "# Load post-processing algorithm that equalizes the odds\n",
    "# Learn parameters with debias set to False\n",
    "sess = tf.Session()\n",
    "plain_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='plain_classifier_part_1',\n",
    "                          debias=False,\n",
    "                          sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02yOEOERBmKJ",
    "outputId": "3bb05b7f-6053-4a0d-9ef0-dc5dd5923f4c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.720402\n",
      "epoch 0; iter: 200; batch classifier loss: 0.407042\n",
      "epoch 1; iter: 0; batch classifier loss: 0.361959\n",
      "epoch 1; iter: 200; batch classifier loss: 0.437485\n",
      "epoch 2; iter: 0; batch classifier loss: 0.480875\n",
      "epoch 2; iter: 200; batch classifier loss: 0.456051\n",
      "epoch 3; iter: 0; batch classifier loss: 0.405031\n",
      "epoch 3; iter: 200; batch classifier loss: 0.341224\n",
      "epoch 4; iter: 0; batch classifier loss: 0.335127\n",
      "epoch 4; iter: 200; batch classifier loss: 0.392714\n",
      "epoch 5; iter: 0; batch classifier loss: 0.491046\n",
      "epoch 5; iter: 200; batch classifier loss: 0.359802\n",
      "epoch 6; iter: 0; batch classifier loss: 0.407765\n",
      "epoch 6; iter: 200; batch classifier loss: 0.339861\n",
      "epoch 7; iter: 0; batch classifier loss: 0.412609\n",
      "epoch 7; iter: 200; batch classifier loss: 0.466955\n",
      "epoch 8; iter: 0; batch classifier loss: 0.375506\n",
      "epoch 8; iter: 200; batch classifier loss: 0.368174\n",
      "epoch 9; iter: 0; batch classifier loss: 0.452794\n",
      "epoch 9; iter: 200; batch classifier loss: 0.360016\n",
      "epoch 10; iter: 0; batch classifier loss: 0.357388\n",
      "epoch 10; iter: 200; batch classifier loss: 0.372595\n",
      "epoch 11; iter: 0; batch classifier loss: 0.407882\n",
      "epoch 11; iter: 200; batch classifier loss: 0.429657\n",
      "epoch 12; iter: 0; batch classifier loss: 0.439970\n",
      "epoch 12; iter: 200; batch classifier loss: 0.397106\n",
      "epoch 13; iter: 0; batch classifier loss: 0.414627\n",
      "epoch 13; iter: 200; batch classifier loss: 0.494460\n",
      "epoch 14; iter: 0; batch classifier loss: 0.447730\n",
      "epoch 14; iter: 200; batch classifier loss: 0.301898\n",
      "epoch 15; iter: 0; batch classifier loss: 0.382302\n",
      "epoch 15; iter: 200; batch classifier loss: 0.453237\n",
      "epoch 16; iter: 0; batch classifier loss: 0.397777\n",
      "epoch 16; iter: 200; batch classifier loss: 0.424673\n",
      "epoch 17; iter: 0; batch classifier loss: 0.391509\n",
      "epoch 17; iter: 200; batch classifier loss: 0.425758\n",
      "epoch 18; iter: 0; batch classifier loss: 0.477724\n",
      "epoch 18; iter: 200; batch classifier loss: 0.387291\n",
      "epoch 19; iter: 0; batch classifier loss: 0.457030\n",
      "epoch 19; iter: 200; batch classifier loss: 0.417751\n",
      "epoch 20; iter: 0; batch classifier loss: 0.441797\n",
      "epoch 20; iter: 200; batch classifier loss: 0.405764\n",
      "epoch 21; iter: 0; batch classifier loss: 0.405428\n",
      "epoch 21; iter: 200; batch classifier loss: 0.403910\n",
      "epoch 22; iter: 0; batch classifier loss: 0.375224\n",
      "epoch 22; iter: 200; batch classifier loss: 0.419673\n",
      "epoch 23; iter: 0; batch classifier loss: 0.533660\n",
      "epoch 23; iter: 200; batch classifier loss: 0.371291\n",
      "epoch 24; iter: 0; batch classifier loss: 0.406828\n",
      "epoch 24; iter: 200; batch classifier loss: 0.488163\n",
      "epoch 25; iter: 0; batch classifier loss: 0.346103\n",
      "epoch 25; iter: 200; batch classifier loss: 0.452395\n",
      "epoch 26; iter: 0; batch classifier loss: 0.412668\n",
      "epoch 26; iter: 200; batch classifier loss: 0.363631\n",
      "epoch 27; iter: 0; batch classifier loss: 0.402389\n",
      "epoch 27; iter: 200; batch classifier loss: 0.489910\n",
      "epoch 28; iter: 0; batch classifier loss: 0.372941\n",
      "epoch 28; iter: 200; batch classifier loss: 0.486320\n",
      "epoch 29; iter: 0; batch classifier loss: 0.320363\n",
      "epoch 29; iter: 200; batch classifier loss: 0.328827\n",
      "epoch 30; iter: 0; batch classifier loss: 0.365005\n",
      "epoch 30; iter: 200; batch classifier loss: 0.360580\n",
      "epoch 31; iter: 0; batch classifier loss: 0.375242\n",
      "epoch 31; iter: 200; batch classifier loss: 0.438564\n",
      "epoch 32; iter: 0; batch classifier loss: 0.425088\n",
      "epoch 32; iter: 200; batch classifier loss: 0.458704\n",
      "epoch 33; iter: 0; batch classifier loss: 0.337520\n",
      "epoch 33; iter: 200; batch classifier loss: 0.441541\n",
      "epoch 34; iter: 0; batch classifier loss: 0.376818\n",
      "epoch 34; iter: 200; batch classifier loss: 0.364216\n",
      "epoch 35; iter: 0; batch classifier loss: 0.426272\n",
      "epoch 35; iter: 200; batch classifier loss: 0.481763\n",
      "epoch 36; iter: 0; batch classifier loss: 0.456236\n",
      "epoch 36; iter: 200; batch classifier loss: 0.414621\n",
      "epoch 37; iter: 0; batch classifier loss: 0.422252\n",
      "epoch 37; iter: 200; batch classifier loss: 0.374012\n",
      "epoch 38; iter: 0; batch classifier loss: 0.361711\n",
      "epoch 38; iter: 200; batch classifier loss: 0.452972\n",
      "epoch 39; iter: 0; batch classifier loss: 0.489286\n",
      "epoch 39; iter: 200; batch classifier loss: 0.402996\n",
      "epoch 40; iter: 0; batch classifier loss: 0.391851\n",
      "epoch 40; iter: 200; batch classifier loss: 0.416570\n",
      "epoch 41; iter: 0; batch classifier loss: 0.419140\n",
      "epoch 41; iter: 200; batch classifier loss: 0.438240\n",
      "epoch 42; iter: 0; batch classifier loss: 0.349720\n",
      "epoch 42; iter: 200; batch classifier loss: 0.451622\n",
      "epoch 43; iter: 0; batch classifier loss: 0.421146\n",
      "epoch 43; iter: 200; batch classifier loss: 0.464925\n",
      "epoch 44; iter: 0; batch classifier loss: 0.491823\n",
      "epoch 44; iter: 200; batch classifier loss: 0.411421\n",
      "epoch 45; iter: 0; batch classifier loss: 0.472126\n",
      "epoch 45; iter: 200; batch classifier loss: 0.336557\n",
      "epoch 46; iter: 0; batch classifier loss: 0.486344\n",
      "epoch 46; iter: 200; batch classifier loss: 0.452862\n",
      "epoch 47; iter: 0; batch classifier loss: 0.376278\n",
      "epoch 47; iter: 200; batch classifier loss: 0.320042\n",
      "epoch 48; iter: 0; batch classifier loss: 0.484151\n",
      "epoch 48; iter: 200; batch classifier loss: 0.463232\n",
      "epoch 49; iter: 0; batch classifier loss: 0.409596\n",
      "epoch 49; iter: 200; batch classifier loss: 0.445260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x7feab461ba60>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_model.fit(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5W4SfmqcBmKJ"
   },
   "outputs": [],
   "source": [
    "# Apply the plain model to test data\n",
    "dataset_nodebiasing_train = plain_model.predict(dataset_orig_train)\n",
    "dataset_nodebiasing_test = plain_model.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "QubARVjWBmKJ",
    "outputId": "f5250919-6a8d-4964-bcd0-b9a1a9f07725"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.209740\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.214823\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.798403\n",
      "Test set: Classification precision = 0.656886\n",
      "Test set: Classification recall = 0.383743\n",
      "TPR: True Positive Rate = 0.383743\n",
      "TNR: True Negative Rate = 0.934306\n",
      "FPR: False Positive Rate = 0.065694\n",
      "FNR: False Negative Rate = 0.616257\n",
      "Test set: Balanced classification accuracy = 0.659025\n",
      "Test set: Disparate impact = 0.000000\n",
      "Test set: Equal opportunity difference = -0.451235\n",
      "Test set: Average odds difference = -0.279242\n",
      "Test set: Theil_index = 0.184736\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "metric_dataset_nodebiasing_train = BinaryLabelDatasetMetric(dataset_nodebiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(dataset_nodebiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "classified_metric_nodebiasing_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_nodebiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "print(\"Test set: Classification precision = %f\" % classified_metric_nodebiasing_test.precision())\n",
    "print(\"Test set: Classification recall = %f\" % classified_metric_nodebiasing_test.recall())\n",
    "\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "FPR = classified_metric_nodebiasing_test.false_positive_rate()\n",
    "FNR = classified_metric_nodebiasing_test.false_negative_rate()\n",
    "print(\"TPR: True Positive Rate = %f\" % TPR)\n",
    "print(\"TNR: True Negative Rate = %f\" % TNR)\n",
    "print(\"FPR: False Positive Rate = %f\" % FPR)\n",
    "print(\"FNR: False Negative Rate = %f\" % FNR)\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1vjwtxjBmKK"
   },
   "source": [
    "### Apply in-processing algorithm based on adversarial learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "1zeMb4wZBmKK"
   },
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "AqM564LRBmKK"
   },
   "outputs": [],
   "source": [
    "# Learn parameters with debias set to True\n",
    "debiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='debiased_classifier_part_1',\n",
    "                          debias=True,\n",
    "                          sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BMu_2cZ-BmKL",
    "outputId": "43b1fc0a-6f8d-4640-c73e-f1c498fd63f2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.759828; batch adversarial loss: 0.661721\n",
      "epoch 0; iter: 200; batch classifier loss: 0.543180; batch adversarial loss: 0.649956\n",
      "epoch 1; iter: 0; batch classifier loss: 0.491863; batch adversarial loss: 0.682094\n",
      "epoch 1; iter: 200; batch classifier loss: 0.459154; batch adversarial loss: 0.649397\n",
      "epoch 2; iter: 0; batch classifier loss: 0.490993; batch adversarial loss: 0.623625\n",
      "epoch 2; iter: 200; batch classifier loss: 0.464788; batch adversarial loss: 0.646605\n",
      "epoch 3; iter: 0; batch classifier loss: 0.444911; batch adversarial loss: 0.641664\n",
      "epoch 3; iter: 200; batch classifier loss: 0.454854; batch adversarial loss: 0.589226\n",
      "epoch 4; iter: 0; batch classifier loss: 0.409471; batch adversarial loss: 0.563411\n",
      "epoch 4; iter: 200; batch classifier loss: 0.408660; batch adversarial loss: 0.608686\n",
      "epoch 5; iter: 0; batch classifier loss: 0.409663; batch adversarial loss: 0.638049\n",
      "epoch 5; iter: 200; batch classifier loss: 0.423042; batch adversarial loss: 0.633316\n",
      "epoch 6; iter: 0; batch classifier loss: 0.432792; batch adversarial loss: 0.572669\n",
      "epoch 6; iter: 200; batch classifier loss: 0.488844; batch adversarial loss: 0.653281\n",
      "epoch 7; iter: 0; batch classifier loss: 0.456157; batch adversarial loss: 0.683162\n",
      "epoch 7; iter: 200; batch classifier loss: 0.388410; batch adversarial loss: 0.584902\n",
      "epoch 8; iter: 0; batch classifier loss: 0.392698; batch adversarial loss: 0.598090\n",
      "epoch 8; iter: 200; batch classifier loss: 0.427080; batch adversarial loss: 0.622040\n",
      "epoch 9; iter: 0; batch classifier loss: 0.330772; batch adversarial loss: 0.587082\n",
      "epoch 9; iter: 200; batch classifier loss: 0.441107; batch adversarial loss: 0.642647\n",
      "epoch 10; iter: 0; batch classifier loss: 0.516407; batch adversarial loss: 0.639106\n",
      "epoch 10; iter: 200; batch classifier loss: 0.400474; batch adversarial loss: 0.640723\n",
      "epoch 11; iter: 0; batch classifier loss: 0.386546; batch adversarial loss: 0.606838\n",
      "epoch 11; iter: 200; batch classifier loss: 0.425216; batch adversarial loss: 0.599930\n",
      "epoch 12; iter: 0; batch classifier loss: 0.359040; batch adversarial loss: 0.581891\n",
      "epoch 12; iter: 200; batch classifier loss: 0.474436; batch adversarial loss: 0.588787\n",
      "epoch 13; iter: 0; batch classifier loss: 0.421059; batch adversarial loss: 0.640704\n",
      "epoch 13; iter: 200; batch classifier loss: 0.418559; batch adversarial loss: 0.630057\n",
      "epoch 14; iter: 0; batch classifier loss: 0.407413; batch adversarial loss: 0.642177\n",
      "epoch 14; iter: 200; batch classifier loss: 0.424837; batch adversarial loss: 0.624600\n",
      "epoch 15; iter: 0; batch classifier loss: 0.442553; batch adversarial loss: 0.613652\n",
      "epoch 15; iter: 200; batch classifier loss: 0.430757; batch adversarial loss: 0.591305\n",
      "epoch 16; iter: 0; batch classifier loss: 0.413538; batch adversarial loss: 0.638950\n",
      "epoch 16; iter: 200; batch classifier loss: 0.480594; batch adversarial loss: 0.554091\n",
      "epoch 17; iter: 0; batch classifier loss: 0.389297; batch adversarial loss: 0.645739\n",
      "epoch 17; iter: 200; batch classifier loss: 0.388353; batch adversarial loss: 0.609963\n",
      "epoch 18; iter: 0; batch classifier loss: 0.482714; batch adversarial loss: 0.652097\n",
      "epoch 18; iter: 200; batch classifier loss: 0.360246; batch adversarial loss: 0.607083\n",
      "epoch 19; iter: 0; batch classifier loss: 0.414243; batch adversarial loss: 0.612275\n",
      "epoch 19; iter: 200; batch classifier loss: 0.428737; batch adversarial loss: 0.569746\n",
      "epoch 20; iter: 0; batch classifier loss: 0.514808; batch adversarial loss: 0.577729\n",
      "epoch 20; iter: 200; batch classifier loss: 0.458264; batch adversarial loss: 0.573793\n",
      "epoch 21; iter: 0; batch classifier loss: 0.450629; batch adversarial loss: 0.593602\n",
      "epoch 21; iter: 200; batch classifier loss: 0.392465; batch adversarial loss: 0.568886\n",
      "epoch 22; iter: 0; batch classifier loss: 0.401530; batch adversarial loss: 0.569516\n",
      "epoch 22; iter: 200; batch classifier loss: 0.485607; batch adversarial loss: 0.600458\n",
      "epoch 23; iter: 0; batch classifier loss: 0.379045; batch adversarial loss: 0.600398\n",
      "epoch 23; iter: 200; batch classifier loss: 0.408872; batch adversarial loss: 0.593203\n",
      "epoch 24; iter: 0; batch classifier loss: 0.411928; batch adversarial loss: 0.628431\n",
      "epoch 24; iter: 200; batch classifier loss: 0.394602; batch adversarial loss: 0.611689\n",
      "epoch 25; iter: 0; batch classifier loss: 0.442638; batch adversarial loss: 0.607520\n",
      "epoch 25; iter: 200; batch classifier loss: 0.444454; batch adversarial loss: 0.581680\n",
      "epoch 26; iter: 0; batch classifier loss: 0.360738; batch adversarial loss: 0.607105\n",
      "epoch 26; iter: 200; batch classifier loss: 0.427161; batch adversarial loss: 0.623552\n",
      "epoch 27; iter: 0; batch classifier loss: 0.394361; batch adversarial loss: 0.606730\n",
      "epoch 27; iter: 200; batch classifier loss: 0.420072; batch adversarial loss: 0.542470\n",
      "epoch 28; iter: 0; batch classifier loss: 0.352984; batch adversarial loss: 0.636810\n",
      "epoch 28; iter: 200; batch classifier loss: 0.380665; batch adversarial loss: 0.635741\n",
      "epoch 29; iter: 0; batch classifier loss: 0.497517; batch adversarial loss: 0.661010\n",
      "epoch 29; iter: 200; batch classifier loss: 0.383153; batch adversarial loss: 0.575549\n",
      "epoch 30; iter: 0; batch classifier loss: 0.441408; batch adversarial loss: 0.637900\n",
      "epoch 30; iter: 200; batch classifier loss: 0.420395; batch adversarial loss: 0.601642\n",
      "epoch 31; iter: 0; batch classifier loss: 0.437370; batch adversarial loss: 0.585287\n",
      "epoch 31; iter: 200; batch classifier loss: 0.432868; batch adversarial loss: 0.604522\n",
      "epoch 32; iter: 0; batch classifier loss: 0.481593; batch adversarial loss: 0.583065\n",
      "epoch 32; iter: 200; batch classifier loss: 0.404837; batch adversarial loss: 0.574579\n",
      "epoch 33; iter: 0; batch classifier loss: 0.438782; batch adversarial loss: 0.599505\n",
      "epoch 33; iter: 200; batch classifier loss: 0.374081; batch adversarial loss: 0.642765\n",
      "epoch 34; iter: 0; batch classifier loss: 0.477244; batch adversarial loss: 0.611955\n",
      "epoch 34; iter: 200; batch classifier loss: 0.391119; batch adversarial loss: 0.570449\n",
      "epoch 35; iter: 0; batch classifier loss: 0.464945; batch adversarial loss: 0.621999\n",
      "epoch 35; iter: 200; batch classifier loss: 0.455226; batch adversarial loss: 0.732162\n",
      "epoch 36; iter: 0; batch classifier loss: 0.429898; batch adversarial loss: 0.555084\n",
      "epoch 36; iter: 200; batch classifier loss: 0.504493; batch adversarial loss: 0.588231\n",
      "epoch 37; iter: 0; batch classifier loss: 0.282065; batch adversarial loss: 0.628801\n",
      "epoch 37; iter: 200; batch classifier loss: 0.419385; batch adversarial loss: 0.599433\n",
      "epoch 38; iter: 0; batch classifier loss: 0.409219; batch adversarial loss: 0.610933\n",
      "epoch 38; iter: 200; batch classifier loss: 0.378450; batch adversarial loss: 0.604570\n",
      "epoch 39; iter: 0; batch classifier loss: 0.353169; batch adversarial loss: 0.685699\n",
      "epoch 39; iter: 200; batch classifier loss: 0.577848; batch adversarial loss: 0.611851\n",
      "epoch 40; iter: 0; batch classifier loss: 0.307270; batch adversarial loss: 0.640353\n",
      "epoch 40; iter: 200; batch classifier loss: 0.492280; batch adversarial loss: 0.566908\n",
      "epoch 41; iter: 0; batch classifier loss: 0.425078; batch adversarial loss: 0.603693\n",
      "epoch 41; iter: 200; batch classifier loss: 0.450408; batch adversarial loss: 0.646848\n",
      "epoch 42; iter: 0; batch classifier loss: 0.434968; batch adversarial loss: 0.530884\n",
      "epoch 42; iter: 200; batch classifier loss: 0.438363; batch adversarial loss: 0.600380\n",
      "epoch 43; iter: 0; batch classifier loss: 0.407435; batch adversarial loss: 0.627726\n",
      "epoch 43; iter: 200; batch classifier loss: 0.430631; batch adversarial loss: 0.678400\n",
      "epoch 44; iter: 0; batch classifier loss: 0.414942; batch adversarial loss: 0.615971\n",
      "epoch 44; iter: 200; batch classifier loss: 0.444667; batch adversarial loss: 0.605705\n",
      "epoch 45; iter: 0; batch classifier loss: 0.405813; batch adversarial loss: 0.615326\n",
      "epoch 45; iter: 200; batch classifier loss: 0.429467; batch adversarial loss: 0.566638\n",
      "epoch 46; iter: 0; batch classifier loss: 0.305157; batch adversarial loss: 0.592450\n",
      "epoch 46; iter: 200; batch classifier loss: 0.458519; batch adversarial loss: 0.592918\n",
      "epoch 47; iter: 0; batch classifier loss: 0.511870; batch adversarial loss: 0.561661\n",
      "epoch 47; iter: 200; batch classifier loss: 0.523474; batch adversarial loss: 0.590973\n",
      "epoch 48; iter: 0; batch classifier loss: 0.436339; batch adversarial loss: 0.613237\n",
      "epoch 48; iter: 200; batch classifier loss: 0.429411; batch adversarial loss: 0.644450\n",
      "epoch 49; iter: 0; batch classifier loss: 0.455125; batch adversarial loss: 0.585150\n",
      "epoch 49; iter: 200; batch classifier loss: 0.457503; batch adversarial loss: 0.528493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x7feab41df790>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debiased_model.fit(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "qI6UtbIiBmKL"
   },
   "outputs": [],
   "source": [
    "# Apply the plain model to test data\n",
    "dataset_debiasing_train = debiased_model.predict(dataset_orig_train)\n",
    "dataset_debiasing_test = debiased_model.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 628
    },
    "id": "6AhNHbDHBmKL",
    "outputId": "dc91a65f-52e7-49df-af41-2a3a37ef3e21"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.209740\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.214823\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.136748\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.142406\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.798403\n",
      "Test set: Classification precision = 0.656886\n",
      "Test set: Classification recall = 0.383743\n",
      "TPR: True Positive Rate = 0.383743\n",
      "TNR: True Negative Rate = 0.934306\n",
      "FPR: False Positive Rate = 0.065694\n",
      "FNR: False Negative Rate = 0.616257\n",
      "Test set: Balanced classification accuracy = 0.659025\n",
      "Test set: Disparate impact = 0.000000\n",
      "Test set: Equal opportunity difference = -0.451235\n",
      "Test set: Average odds difference = -0.279242\n",
      "Test set: Theil_index = 0.184736\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.791169\n",
      "TPR: True Positive Rate = 0.383743\n",
      "TNR: True Negative Rate = 0.934306\n",
      "FPR: False Positive Rate = 0.065694\n",
      "FNR: False Negative Rate = 0.616257\n",
      "Test set: Balanced classification accuracy = 0.659025\n",
      "Test set: Disparate impact = 0.316061\n",
      "Test set: Equal opportunity difference = -0.244574\n",
      "Test set: Average odds difference = -0.148872\n",
      "Test set: Theil_index = 0.182832\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "# Metrics for the dataset from model with debiasing\n",
    "display(Markdown(\"#### Model - with debiasing - dataset metrics\"))\n",
    "metric_dataset_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_test.mean_difference())\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "print(\"Test set: Classification precision = %f\" % classified_metric_nodebiasing_test.precision())\n",
    "print(\"Test set: Classification recall = %f\" % classified_metric_nodebiasing_test.recall())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "FPR = classified_metric_nodebiasing_test.false_positive_rate()\n",
    "FNR = classified_metric_nodebiasing_test.false_negative_rate()\n",
    "print(\"TPR: True Positive Rate = %f\" % TPR)\n",
    "print(\"TNR: True Negative Rate = %f\" % TNR)\n",
    "print(\"FPR: False Positive Rate = %f\" % FPR)\n",
    "print(\"FNR: False Negative Rate = %f\" % FNR)\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Model - with debiasing - classification metrics\"))\n",
    "classified_metric_debiasing_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_debiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "FPR = classified_metric_nodebiasing_test.false_positive_rate()\n",
    "FNR = classified_metric_nodebiasing_test.false_negative_rate()\n",
    "print(\"TPR: True Positive Rate = %f\" % TPR)\n",
    "print(\"TNR: True Negative Rate = %f\" % TNR)\n",
    "print(\"FPR: False Positive Rate = %f\" % FPR)\n",
    "print(\"FNR: False Negative Rate = %f\" % FNR)\n",
    "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_debiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_debiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_debiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3iY5M7oCBmKM"
   },
   "source": [
    "# Part 2: Preprocessing dataset using MinMaxScaler</br>\n",
    "StandardScaler also gives approximately the same results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YsTN6YtBmKS"
   },
   "source": [
    "# Part 3: changing the architecture of the neural network, added 2 additonal layer with the activation function relu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "PYM0KKsbBmKS"
   },
   "outputs": [],
   "source": [
    "from aif360.algorithms.inprocessing.adversarial_debiasing_pg1 import AdversarialDebiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "id": "cWcVZ8JKBmKS",
    "outputId": "d33f73d4-897b-4d1f-bbbe-56477ade02db"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Scaled dataset - Verify that the scaling does not affect the group label statistics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.191948\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.200418\n"
     ]
    }
   ],
   "source": [
    "# Add more data preprocessing here \n",
    "min_max_scaler = MinMaxScaler()\n",
    "dataset_orig_train.features = min_max_scaler.fit_transform(dataset_orig_train.features)\n",
    "dataset_orig_test.features = min_max_scaler.transform(dataset_orig_test.features)\n",
    "metric_scaled_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Scaled dataset - Verify that the scaling does not affect the group label statistics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_train.mean_difference())\n",
    "metric_scaled_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_test.mean_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0nPjZXKBmKS"
   },
   "source": [
    "### Learn plain classifier without debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "2Nfp1LnyBmKS"
   },
   "outputs": [],
   "source": [
    "# Load post-processing algorithm that equalizes the odds\n",
    "# Learn parameters with debias set to False\n",
    "sess = tf.Session()\n",
    "plain_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='plain_classifier_part_3',\n",
    "                          debias=False,\n",
    "                          sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FQFRRddsBmKT",
    "outputId": "0a520c1e-9e68-4cf7-a8f7-5fb82b5b8b6b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.687325\n",
      "epoch 0; iter: 200; batch classifier loss: 0.470102\n",
      "epoch 1; iter: 0; batch classifier loss: 0.550684\n",
      "epoch 1; iter: 200; batch classifier loss: 0.497577\n",
      "epoch 2; iter: 0; batch classifier loss: 0.397570\n",
      "epoch 2; iter: 200; batch classifier loss: 0.399183\n",
      "epoch 3; iter: 0; batch classifier loss: 0.416078\n",
      "epoch 3; iter: 200; batch classifier loss: 0.402656\n",
      "epoch 4; iter: 0; batch classifier loss: 0.422276\n",
      "epoch 4; iter: 200; batch classifier loss: 0.425741\n",
      "epoch 5; iter: 0; batch classifier loss: 0.457593\n",
      "epoch 5; iter: 200; batch classifier loss: 0.377042\n",
      "epoch 6; iter: 0; batch classifier loss: 0.515300\n",
      "epoch 6; iter: 200; batch classifier loss: 0.409753\n",
      "epoch 7; iter: 0; batch classifier loss: 0.427897\n",
      "epoch 7; iter: 200; batch classifier loss: 0.430777\n",
      "epoch 8; iter: 0; batch classifier loss: 0.376762\n",
      "epoch 8; iter: 200; batch classifier loss: 0.433482\n",
      "epoch 9; iter: 0; batch classifier loss: 0.465370\n",
      "epoch 9; iter: 200; batch classifier loss: 0.446604\n",
      "epoch 10; iter: 0; batch classifier loss: 0.375945\n",
      "epoch 10; iter: 200; batch classifier loss: 0.734741\n",
      "epoch 11; iter: 0; batch classifier loss: 0.387232\n",
      "epoch 11; iter: 200; batch classifier loss: 65.986748\n",
      "epoch 12; iter: 0; batch classifier loss: 68.001854\n",
      "epoch 12; iter: 200; batch classifier loss: 31.945459\n",
      "epoch 13; iter: 0; batch classifier loss: 9.398496\n",
      "epoch 13; iter: 200; batch classifier loss: 6.801931\n",
      "epoch 14; iter: 0; batch classifier loss: 14.070862\n",
      "epoch 14; iter: 200; batch classifier loss: 13.970785\n",
      "epoch 15; iter: 0; batch classifier loss: 15.594452\n",
      "epoch 15; iter: 200; batch classifier loss: 17.829063\n",
      "epoch 16; iter: 0; batch classifier loss: 15.732504\n",
      "epoch 16; iter: 200; batch classifier loss: 16.248775\n",
      "epoch 17; iter: 0; batch classifier loss: 5.934124\n",
      "epoch 17; iter: 200; batch classifier loss: 3.371675\n",
      "epoch 18; iter: 0; batch classifier loss: 18.518974\n",
      "epoch 18; iter: 200; batch classifier loss: 14.403069\n",
      "epoch 19; iter: 0; batch classifier loss: 10.671350\n",
      "epoch 19; iter: 200; batch classifier loss: 2.919434\n",
      "epoch 20; iter: 0; batch classifier loss: 8.843431\n",
      "epoch 20; iter: 200; batch classifier loss: 14.541245\n",
      "epoch 21; iter: 0; batch classifier loss: 11.543805\n",
      "epoch 21; iter: 200; batch classifier loss: 3.560473\n",
      "epoch 22; iter: 0; batch classifier loss: 4.540210\n",
      "epoch 22; iter: 200; batch classifier loss: 5.168231\n",
      "epoch 23; iter: 0; batch classifier loss: 2.040995\n",
      "epoch 23; iter: 200; batch classifier loss: 2.927728\n",
      "epoch 24; iter: 0; batch classifier loss: 2.587284\n",
      "epoch 24; iter: 200; batch classifier loss: 2.208058\n",
      "epoch 25; iter: 0; batch classifier loss: 4.067185\n",
      "epoch 25; iter: 200; batch classifier loss: 3.760564\n",
      "epoch 26; iter: 0; batch classifier loss: 2.659660\n",
      "epoch 26; iter: 200; batch classifier loss: 3.721421\n",
      "epoch 27; iter: 0; batch classifier loss: 2.257256\n",
      "epoch 27; iter: 200; batch classifier loss: 3.395134\n",
      "epoch 28; iter: 0; batch classifier loss: 2.745183\n",
      "epoch 28; iter: 200; batch classifier loss: 2.259810\n",
      "epoch 29; iter: 0; batch classifier loss: 3.626838\n",
      "epoch 29; iter: 200; batch classifier loss: 4.520951\n",
      "epoch 30; iter: 0; batch classifier loss: 3.177800\n",
      "epoch 30; iter: 200; batch classifier loss: 3.354076\n",
      "epoch 31; iter: 0; batch classifier loss: 1.657869\n",
      "epoch 31; iter: 200; batch classifier loss: 1.294822\n",
      "epoch 32; iter: 0; batch classifier loss: 3.941934\n",
      "epoch 32; iter: 200; batch classifier loss: 2.551117\n",
      "epoch 33; iter: 0; batch classifier loss: 2.395140\n",
      "epoch 33; iter: 200; batch classifier loss: 0.711682\n",
      "epoch 34; iter: 0; batch classifier loss: 1.167344\n",
      "epoch 34; iter: 200; batch classifier loss: 6.624094\n",
      "epoch 35; iter: 0; batch classifier loss: 1.596829\n",
      "epoch 35; iter: 200; batch classifier loss: 0.860357\n",
      "epoch 36; iter: 0; batch classifier loss: 3.961234\n",
      "epoch 36; iter: 200; batch classifier loss: 0.763135\n",
      "epoch 37; iter: 0; batch classifier loss: 0.550988\n",
      "epoch 37; iter: 200; batch classifier loss: 3.709104\n",
      "epoch 38; iter: 0; batch classifier loss: 3.750732\n",
      "epoch 38; iter: 200; batch classifier loss: 0.422408\n",
      "epoch 39; iter: 0; batch classifier loss: 0.823567\n",
      "epoch 39; iter: 200; batch classifier loss: 0.960444\n",
      "epoch 40; iter: 0; batch classifier loss: 16.036165\n",
      "epoch 40; iter: 200; batch classifier loss: 9.790880\n",
      "epoch 41; iter: 0; batch classifier loss: 5.315099\n",
      "epoch 41; iter: 200; batch classifier loss: 4.862730\n",
      "epoch 42; iter: 0; batch classifier loss: 2.565994\n",
      "epoch 42; iter: 200; batch classifier loss: 4.369214\n",
      "epoch 43; iter: 0; batch classifier loss: 1.520716\n",
      "epoch 43; iter: 200; batch classifier loss: 2.605941\n",
      "epoch 44; iter: 0; batch classifier loss: 1.412490\n",
      "epoch 44; iter: 200; batch classifier loss: 1.860626\n",
      "epoch 45; iter: 0; batch classifier loss: 1.120535\n",
      "epoch 45; iter: 200; batch classifier loss: 1.669161\n",
      "epoch 46; iter: 0; batch classifier loss: 1.128938\n",
      "epoch 46; iter: 200; batch classifier loss: 1.341059\n",
      "epoch 47; iter: 0; batch classifier loss: 2.550440\n",
      "epoch 47; iter: 200; batch classifier loss: 0.803675\n",
      "epoch 48; iter: 0; batch classifier loss: 1.442381\n",
      "epoch 48; iter: 200; batch classifier loss: 1.527347\n",
      "epoch 49; iter: 0; batch classifier loss: 0.690433\n",
      "epoch 49; iter: 200; batch classifier loss: 1.058060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing_pg1.AdversarialDebiasing at 0x7feaa0234ac0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_model.fit(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "z2ZJdiasBmKT"
   },
   "outputs": [],
   "source": [
    "# Apply the plain model to test data\n",
    "dataset_nodebiasing_train = plain_model.predict(dataset_orig_train)\n",
    "dataset_nodebiasing_test = plain_model.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "MjGSOoueBmKT",
    "outputId": "1e2558dc-bf89-46b1-be37-f3d8b2b02de5"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.753156\n",
      "Test set: Classification precision = 0.000000\n",
      "Test set: Classification recall = 0.000000\n",
      "TPR: True Positive Rate = 0.000000\n",
      "TNR: True Negative Rate = 1.000000\n",
      "FPR: False Positive Rate = 0.000000\n",
      "FNR: False Negative Rate = 1.000000\n",
      "Test set: Balanced classification accuracy = 0.500000\n",
      "Test set: Disparate impact = nan\n",
      "Test set: Equal opportunity difference = 0.000000\n",
      "Test set: Average odds difference = 0.000000\n",
      "Test set: Theil_index = 0.283482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "metric_dataset_nodebiasing_train = BinaryLabelDatasetMetric(dataset_nodebiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(dataset_nodebiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "classified_metric_nodebiasing_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_nodebiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "print(\"Test set: Classification precision = %f\" % classified_metric_nodebiasing_test.precision())\n",
    "print(\"Test set: Classification recall = %f\" % classified_metric_nodebiasing_test.recall())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "FPR = classified_metric_nodebiasing_test.false_positive_rate()\n",
    "FNR = classified_metric_nodebiasing_test.false_negative_rate()\n",
    "print(\"TPR: True Positive Rate = %f\" % TPR)\n",
    "print(\"TNR: True Negative Rate = %f\" % TNR)\n",
    "print(\"FPR: False Positive Rate = %f\" % FPR)\n",
    "print(\"FNR: False Negative Rate = %f\" % FNR)\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KlmAWAQhBmKT"
   },
   "source": [
    "### Apply in-processing algorithm based on adversarial learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "leQnVRAABmKT"
   },
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "yHLAWttNBmKT"
   },
   "outputs": [],
   "source": [
    "# Learn parameters with debias set to True\n",
    "debiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='debiased_classifier_part_2',\n",
    "                          debias=True,\n",
    "                          sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h8oOIZVZBmKU",
    "outputId": "dad5f4d8-2835-4a84-ecf6-000cdf29726a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.681401; batch adversarial loss: 0.649939\n",
      "epoch 0; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 1; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 1; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 2; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 2; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 3; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 3; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 4; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 4; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 5; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 5; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 6; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 6; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 7; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 7; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 8; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 8; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 9; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 9; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 10; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 10; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 11; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 11; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 12; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 12; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 13; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 13; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 14; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 14; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 15; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 15; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 16; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 16; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 17; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 17; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 18; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 18; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 19; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 19; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 20; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 20; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 21; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 21; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 22; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 22; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 23; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 23; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 24; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 24; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 25; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 25; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 26; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 26; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 27; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 27; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 28; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 28; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 29; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 29; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 30; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 30; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 31; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 31; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 32; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 32; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 33; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 33; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 34; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 34; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 35; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 35; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 36; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 36; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 37; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 37; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 38; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 38; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 39; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 39; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 40; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 40; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 41; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 41; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 42; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 42; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 43; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 43; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 44; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 44; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 45; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 45; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 46; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 46; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 47; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 47; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 48; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 48; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 49; iter: 0; batch classifier loss: nan; batch adversarial loss: nan\n",
      "epoch 49; iter: 200; batch classifier loss: nan; batch adversarial loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing_pg1.AdversarialDebiasing at 0x7feaa02cef40>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debiased_model.fit(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "hP_gJ5aEBmKU"
   },
   "outputs": [],
   "source": [
    "# Apply the plain model to test data\n",
    "dataset_debiasing_train = debiased_model.predict(dataset_orig_train)\n",
    "dataset_debiasing_test = debiased_model.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 628
    },
    "id": "WHMFWhnjBmKU",
    "outputId": "d76d4f6d-32d8-432a-9850-466ebb642672"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.753156\n",
      "Test set: Classification precision = 0.000000\n",
      "Test set: Classification recall = 0.000000\n",
      "TPR: True Positive Rate = 0.000000\n",
      "TNR: True Negative Rate = 1.000000\n",
      "FPR: False Positive Rate = 0.000000\n",
      "FNR: False Negative Rate = 1.000000\n",
      "Test set: Balanced classification accuracy = 0.500000\n",
      "Test set: Disparate impact = nan\n",
      "Test set: Equal opportunity difference = 0.000000\n",
      "Test set: Average odds difference = 0.000000\n",
      "Test set: Theil_index = 0.283482\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.753156\n",
      "TPR: True Positive Rate = 0.000000\n",
      "TNR: True Negative Rate = 1.000000\n",
      "FPR: False Positive Rate = 0.000000\n",
      "FNR: False Negative Rate = 1.000000\n",
      "Test set: Balanced classification accuracy = 0.500000\n",
      "Test set: Disparate impact = nan\n",
      "Test set: Equal opportunity difference = 0.000000\n",
      "Test set: Average odds difference = 0.000000\n",
      "Test set: Theil_index = 0.283482\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "# Metrics for the dataset from model with debiasing\n",
    "display(Markdown(\"#### Model - with debiasing - dataset metrics\"))\n",
    "metric_dataset_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_test.mean_difference())\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "print(\"Test set: Classification precision = %f\" % classified_metric_nodebiasing_test.precision())\n",
    "print(\"Test set: Classification recall = %f\" % classified_metric_nodebiasing_test.recall())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "FPR = classified_metric_nodebiasing_test.false_positive_rate()\n",
    "FNR = classified_metric_nodebiasing_test.false_negative_rate()\n",
    "print(\"TPR: True Positive Rate = %f\" % TPR)\n",
    "print(\"TNR: True Negative Rate = %f\" % TNR)\n",
    "print(\"FPR: False Positive Rate = %f\" % FPR)\n",
    "print(\"FNR: False Negative Rate = %f\" % FNR)\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Model - with debiasing - classification metrics\"))\n",
    "classified_metric_debiasing_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_debiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "FPR = classified_metric_nodebiasing_test.false_positive_rate()\n",
    "FNR = classified_metric_nodebiasing_test.false_negative_rate()\n",
    "\n",
    "print(\"TPR: True Positive Rate = %f\" % TPR)\n",
    "print(\"TNR: True Negative Rate = %f\" % TNR)\n",
    "print(\"FPR: False Positive Rate = %f\" % FPR)\n",
    "print(\"FNR: False Negative Rate = %f\" % FNR)\n",
    "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_debiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_debiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_debiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "_MvNxn1y5e5N"
   },
   "outputs": [],
   "source": [
    "# #PLOT ROC curve\n",
    "# # plt.plot(FPR,TPR)\n",
    "# plt.plot(FPR, TPR, 'k--', label='ROC curve (area = %0.3f)')\n",
    "# # plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.0])\n",
    "# plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
    "# plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "# plt.title('Receiver Operating Characteristic')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()\n",
    "\n",
    "# # from sklearn.metrics import roc_curve\n",
    "# # from sklearn.metrics import auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVHTRbOsBmKU"
   },
   "source": [
    "\n",
    "    References:\n",
    "    [1] B. H. Zhang, B. Lemoine, and M. Mitchell, \"Mitigating UnwantedBiases with Adversarial Learning,\" \n",
    "    AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, 2018."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
